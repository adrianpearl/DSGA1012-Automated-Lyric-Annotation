{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the artists schema, this script iterates over artistID's and gets the corresponding list of songID's, then appends each resulting (artistID,songID) pair to the song_ids.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions _get and get_artist_songs() in this code \n",
    "# are courtesy of GitHub user imdkm:\n",
    "# https://gist.github.com/imdkm/a60247b59ff1881fa4bb8846a9b44c96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "from time import sleep\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secret token\n",
    "token = open(\"ACCESS_TOKEN.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values.\n",
    "BASE_URL = \"https://api.genius.com\"\n",
    "CLIENT_ACCESS_TOKEN = token\n",
    "QUERY_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request and get response in json format.\n",
    "def _get(path, params=None, headers=None):\n",
    "\n",
    "    # generate request URL\n",
    "    requrl = '/'.join([BASE_URL, path])\n",
    "    token = \"Bearer {}\".format(CLIENT_ACCESS_TOKEN)\n",
    "    if headers:\n",
    "        headers['Authorization'] = token\n",
    "    else:\n",
    "        headers = {\"Authorization\": token}\n",
    "\n",
    "    response = requests.get(url=requrl, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def get_artist_songs(artist_id):\n",
    "    # initialize variables & a list.\n",
    "    current_page = 1\n",
    "    next_page = True\n",
    "    songs = []\n",
    "\n",
    "    # main loop\n",
    "    while next_page:\n",
    "\n",
    "        path = \"artists/{}/songs/\".format(artist_id)\n",
    "        params = {'page': current_page}\n",
    "        data = _get(path=path, params=params)\n",
    "\n",
    "        page_songs = data['response']['songs']\n",
    "\n",
    "        if page_songs:\n",
    "            # add all the songs of current page,\n",
    "            # and increment current_page value for next loop.\n",
    "            songs += page_songs\n",
    "            current_page += 1\n",
    "        else:\n",
    "            # if page_songs is empty, quit.\n",
    "            next_page = False\n",
    "\n",
    "    # get all the song ids, excluding not-primary-artist songs.\n",
    "    songs = [song[\"id\"] for song in songs\n",
    "             if song[\"primary_artist\"][\"id\"] == artist_id]\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from(artist_id):\n",
    "    with open(\"artists.txt\",\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        i=0\n",
    "        while i < len(lines):\n",
    "            if lines[i].split(',')[0] == str(artist_id):\n",
    "                break\n",
    "            i+=1\n",
    "    return lines[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artists total\n"
     ]
    }
   ],
   "source": [
    "# read in list of artist names\n",
    "    \n",
    "import os.path\n",
    "if os.path.isfile('song_ids.txt'):\n",
    "    l = !wc -l song_ids.txt\n",
    "    if int(l[0].split()[0]) > 0:\n",
    "        s = !tail -1 song_ids.txt\n",
    "        last_artist = s[0].split(',')[0]\n",
    "        artists = get_from(last_artist)\n",
    "    \n",
    "artist_ids = [line.strip().split(',')[0] for line in artists if line.strip().split(',')[0] != 'None']\n",
    "print(str(len(artists))+\" artists total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading\n"
     ]
    }
   ],
   "source": [
    "artist_set = set()\n",
    "with open(\"song_ids.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        artist_id,_ = line.split(',')\n",
    "        artist_set.add(artist_id)\n",
    "\n",
    "print(\"done reading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artist_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329461\n",
      "-> 2 results\n",
      "350433\n",
      "-> 14 results\n",
      "4749\n",
      "-> 186 results\n",
      "6060\n",
      "-> 1 results\n",
      "507\n",
      "507 already queried, skipping\n",
      "365765\n",
      "-> 25 results\n",
      "338591\n",
      "338591 already queried, skipping\n",
      "36594\n",
      "-> 190 results\n",
      "368665\n",
      "-> 6 results\n",
      "2548\n",
      "-> 50 results\n",
      "15740\n",
      "15740 already queried, skipping\n",
      "26507\n",
      "26507 already queried, skipping\n",
      "737\n",
      "-> 114 results\n",
      "30242\n",
      "-> 257 results\n",
      "209879\n",
      "-> 1 results\n",
      "2957\n",
      "2957 already queried, skipping\n",
      "251397\n",
      "-> 184 results\n",
      "1042428\n",
      "-> 45 results\n",
      "368037\n",
      "-> 38 results\n",
      "59441\n",
      "-> 106 results\n",
      "552422\n",
      "-> 36 results\n",
      "332633\n",
      "-> 60 results\n",
      "358379\n",
      "-> 117 results\n",
      "1679\n",
      "-> 67 results\n",
      "66456\n",
      "-> 13 results\n",
      "4\n",
      "4 already queried, skipping\n",
      "11195\n",
      "-> 435 results\n",
      "511335\n",
      "-> 11 results\n",
      "59805\n",
      "-> 120 results\n",
      "482683\n",
      "-> 2 results\n",
      "344478\n",
      "-> 167 results\n",
      "39192\n",
      "-> 2 results\n",
      "353342\n",
      "-> 115 results\n",
      "28089\n",
      "-> 37 results\n",
      "157840\n",
      "-> 78 results\n",
      "16965\n",
      "-> 254 results\n",
      "351663\n",
      "-> 108 results\n",
      "372112\n",
      "-> 22 results\n",
      "152920\n",
      "-> 192 results\n",
      "100951\n",
      "-> 374 results\n",
      "48147\n",
      "48147 already queried, skipping\n",
      "1766\n",
      "-> 6 results\n",
      "385577\n",
      "-> 2 results\n",
      "1128983\n",
      "-> 26 results\n",
      "358170\n",
      "-> 61 results\n",
      "357017\n",
      "-> 88 results\n",
      "363859\n",
      "-> 38 results\n",
      "1692\n",
      "-> 302 results\n",
      "337083\n",
      "-> 108 results\n",
      "358194\n",
      "-> 58 results\n",
      "362596\n",
      "-> 37 results\n",
      "49715\n",
      "-> 106 results\n",
      "1122\n",
      "-> 25 results\n",
      "31528\n",
      "-> 271 results\n",
      "1204\n",
      "-> 159 results\n",
      "12068\n",
      "-> 53 results\n",
      "351372\n",
      "-> 56 results\n",
      "2455\n",
      "-> 113 results\n",
      "5374\n",
      "-> 46 results\n",
      "17764\n",
      "-> 138 results\n",
      "139719\n",
      "-> 219 results\n",
      "142\n",
      "-> 262 results\n",
      "173074\n",
      "-> 249 results\n",
      "48368\n",
      "-> 129 results\n",
      "604\n",
      "604 already queried, skipping\n",
      "3371\n",
      "-> 152 results\n",
      "694\n",
      "-> 485 results\n",
      "40889\n",
      "-> 102 results\n",
      "44395\n",
      "-> 51 results\n",
      "357865\n",
      "-> 50 results\n",
      "357631\n",
      "-> 96 results\n",
      "212631\n",
      "-> 36 results\n",
      "105707\n",
      "-> 137 results\n",
      "459460\n",
      "-> 1 results\n",
      "359284\n",
      "-> 12 results\n",
      "358278\n",
      "-> 66 results\n",
      "370411\n",
      "-> 16 results\n",
      "579476\n",
      "-> 1 results\n",
      "349526\n",
      "-> 64 results\n",
      "344693\n",
      "-> 204 results\n",
      "329672\n",
      "-> 121 results\n",
      "1746\n",
      "-> 101 results\n",
      "87949\n",
      "-> 83 results\n",
      "354275\n",
      "-> 56 results\n",
      "874\n",
      "-> 36 results\n",
      "345695\n",
      "-> 10 results\n",
      "355916\n",
      "-> 60 results\n",
      "353391\n",
      "-> 88 results\n",
      "33010\n",
      "-> 42 results\n",
      "1256\n",
      "-> 152 results\n",
      "349420\n",
      "-> 101 results\n",
      "8457\n",
      "-> 90 results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query only a subset of artists at a time to not overwork server\n",
    "# increment chunk_num on each run\n",
    "    \n",
    "artists_chunk = artist_ids[0:]\n",
    "\n",
    "# populate song ids using artist names\n",
    "for i, artist_id in enumerate(artists_chunk):\n",
    "    #sys.stdout.write('\\r'+str(i).zfill(5))\n",
    "    print(artist_id)\n",
    "    \n",
    "    # check if we've already queried this artist:\n",
    "    if artist_id in artist_set:\n",
    "        print(artist_id + \" already queried, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        artist_set.add(artist_id)\n",
    "\n",
    "    # get all song ids and make a list.\n",
    "    song_ids = [None]\n",
    "    try:\n",
    "        song_ids = get_artist_songs(int(artist_id))\n",
    "        print(\"-> \" + str(len(song_ids))+\" results\")\n",
    "    except:\n",
    "        print(\"NOT FOUND\")\n",
    "\n",
    "    with open(\"song_ids.txt\", \"a\") as f:\n",
    "        for song_id in song_ids:\n",
    "            f.write(str(artist_id)+\",\"+str(song_id)+\"\\n\")\n",
    "            \n",
    "    sleep(.5)\n",
    "    \n",
    "os.system('say \"Done\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "songids = pd.read_csv('song_ids.txt', sep=',', names=['artist', 'song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids = songids.drop_duplicates(subset='song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids.to_csv('song_ids_unique.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
